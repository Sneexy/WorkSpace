## 论文笔记：《Learning Task Grouping using Supervised Task Space Partitioning in Lifelong Multitask Learning》

终身多任务学习中基于监督任务空间划分的学习任务分组

评价：这篇论文真的啰嗦繁复，太啰嗦了

创新点：用函数树记录划分函数，为每个任务集寻找划分函数

## ●Abstract

-   question作者想解决什么问题？
    最大的挑战是学习代理可能遇到的未来任务的特征是完全未知的。假设中所有的任务都是相关的，现实中可能从**不相关的任务**中进行训练，导致**信息的负迁移**。
    为了克服这个问题，批处理和在线多任务学习算法都学习任务之间的关系。然而，由于未来任务的未知性质，**学习任务之间的关系**在终身多任务学习中也是困难的。
-   method作者通过什么理论/模型来解决这个问题？
    提出了学习函数来模拟任务关系，因为它在在线环境中计算成本较低。更具体地说，我们学习**任务空间中的划分函数**，以将任务划分为簇。我们的主要贡献是提出一个全局公式来学习任务**划分和参数**。我们提供了一个监督学习框架来估计**划分函数和模型**。
-   answer作者给出的答案是什么？
    性能优越

## ●Instruction

终身多任务学习可以被视为在线多任务学习问题的一个子集，其中框架在任务方面是在线的。

终身多任务学习的灵感来自人类学习的自然过程，因为他们有一种将知识从以前学习的任务转移到新任务的自然趋势。

伊顿等人[7]主要研究了终身多任务学习，他们开发了一种算法，可以处理在训练期间遇到的新任务。作者**假设所有的任务都在一个可以用一组基向量表示的子空间中相关联**。作者的目的是为每个任务**学习这些基向量和这些基向量的系数**。作者以多种方式扩展了这项工作。缺点是当一个新的任务到达时，需要更新整个基向量。此外，这种方法不能在学习任务时进行特征选择。

-   why作者为什么研究这个课题
    在终身学习环境中，**学习任务结构尤其困难**，因为以前没有关于可能到来的新任务的性质的知识。因此，任务学习机制需要是动态的，并且能够随着任务集性质的变化而演变。
-   how当前研究到了哪一阶段
    提出学习**划分函数**而不是任务结构矩阵来学习任务关系。在本文中，我们通过在任务空间上以监督的方式强加一系列的划分来学习任务簇。】
    我们还假设相似的任务依赖于相似的特征。因此，我们也在模型中加入了特征选择。
    该公式**对任务空间进行划分**，使得相似的任务使用监督学习保持在相同的区域中，并**强制相似的任务依赖于相似的特征**。任务参数和关系的学习都是在监督下完成的。我们提出了这个公式的解决方案，使用双重平均技术正则化随机梯度方法来解决稀疏性
-   what作者基于什么样的假设（看不懂最后去查）
    相似的任务依赖于相似的特征

## ●Conclusion

-   优点
    在速度和准确性方面都优于leading终身学习算法
-   缺点
    

## ●Table & Method
本算法命名：SUPART (Supervised partitioning of Tasks)

ELLA:高效终身学习算法，或ELLA，是一种终身多任务学习算法[7]。在该算法中，作者假设所有的任务在一个子空间中是相关的，并学习一组表示任务在其中相关的子空间的基函数。对于每一个任务，基函数的系数也被学习。由于系数被假定为稀疏的，有时也会观察到任务上的重叠聚类效应
-   数据来源
    MNIST Dataset（手写数字图像），USPS Dataset（手写数字图像），Stock Market Dataset（股票），Landmine Detection Dataset（基于位置的雷达图像预测地雷的存在）
-   重要指标
    枚举超参数值，五重交叉验证选择超参数，选择最小的交叉验证值对应的参数，多个超参数时贪婪搜索。
    - 性能比较：平均准确度（正确分类的样本与样本总数的比率）。1-NMSE（标准化均方误差）
    - 时间比较（快）
    - 针对负面信息传递的验证（负面信息没什么影响）
-   模型步骤 + 每个步骤得出的结论
![](Learning%20Task%20Grouping%20using%20Supervised%20Task%20Space%20Partitioning%20in%20Lifelong%20Multitask%20Learning%E7%BB%88%E8%BA%AB%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%9F%BA%E4%BA%8E%E7%9B%91%E7%9D%A3%E4%BB%BB%E5%8A%A1%E7%A9%BA%E9%97%B4%E5%88%92%E5%88%86%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E7%BB%84_md_files/image2.png?v=1&type=image)
	- **任务空间的监督划分**：以监督方式学习划分函数来聚类任务。R为经验损失函数，$u_i$表示区域i中所有任务的通用模型，$v_t$是特定于任务的模型，$\theta$是将输入数据Xt映射到给定任务t的输出yt的函数，代表任务t。l是损失函数，测量均方误差。
![](Learning%20Task%20Grouping%20using%20Supervised%20Task%20Space%20Partitioning%20in%20Lifelong%20Multitask%20Learning%E7%BB%88%E8%BA%AB%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%9F%BA%E4%BA%8E%E7%9B%91%E7%9D%A3%E4%BB%BB%E5%8A%A1%E7%A9%BA%E9%97%B4%E5%88%92%E5%88%86%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E7%BB%84_md_files/image1.png?v=1&type=image)
	- **寻找单分区函数**
	分区i的模型给出较低误差，则标签为i。经验风险是对这些任务进行分类的加权误差
	- **多区域划分的任务空间**
	给定分区函数的值，我们知道给定任务所属的区域。
	- **任务空间的在线划分**
	通过最小损失函数（7），利用随机梯度算法获取$u_i$
	- Algorithm 1里更新partition function的**Algorithm 2**：
	t是第一个任务就作为根结点。
	否则就while循环到叶子节点，更新partition函数g
![](Learning%20Task%20Grouping%20using%20Supervised%20Task%20Space%20Partitioning%20in%20Lifelong%20Multitask%20Learning%E7%BB%88%E8%BA%AB%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E4%B8%AD%E5%9F%BA%E4%BA%8E%E7%9B%91%E7%9D%A3%E4%BB%BB%E5%8A%A1%E7%A9%BA%E9%97%B4%E5%88%92%E5%88%86%E7%9A%84%E5%AD%A6%E4%B9%A0%E4%BB%BB%E5%8A%A1%E5%88%86%E7%BB%84_md_files/image3.png?v=1&type=image)

