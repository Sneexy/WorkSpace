##  论文笔记：《Efficient Meta Lifelong-Learning with Limited Memory》

中译：有限记忆的高效元终身学习

总结：EMNLP。NLP上的终身学习，看看怎么减少负迁移的。

方法：使用存储器M存储样本，每次从中采样到内存作为neighbors，使任务局部适配，减少负迁移。有的样本采样出来又参与了训练，称之为重放，减少了灾难性遗忘。在通用表示步骤中，每加入一个训练样本，通过优化任务损失更新参数θ。在经验排练步骤中，利用key网络g(φ)通过xi到现有内存的最小距离来估计差异，选择和当前内存中的任务差异大的加入存储器M，从而涵盖数据分发的不同部分。对任务损失（通用表示）和重放损失，使用利用$L_{LA}$来限制参数的更新，目的是激发对所有任务的有效本地适应。


## ●Abstract

-   question作者想解决什么问题？

    最先进的终身语言学习方法将过去的例子存储在情节记忆中，并在训练和推理时重放它们。然而，有三个显著的障碍:(1)需要不切实际的大内存模块来实现良好的性能，(2)遭受负迁移，效果比原始效果差(3)每个测试示例需要多个本地自适应步骤，这显著降低了推理速度。
-   method作者通过什么理论/模型来解决这个问题？

    确定了终身学习方法的三个共同原则，并提出了一个有效的元终身框架，以协同的方式将它们结合起来。为了达到样本效率，我们的方法训练模型的方式是，它学习更好的局部适应初始化。
-   answer作者给出的答案是什么？

    在文本分类和问题回答基准上的大量实验证明了我们的框架的有效性，通过仅使用1%的内存大小实现了最先进的性能，并缩小了多任务学习的差距。我们进一步证明了我们的方法同时减轻了灾难性遗忘和负迁移。

## ●Instruction

-   why作者为什么研究这个课题
 
    终身学习有利。其中一个成功方法是用情节记忆模块扩充学习模型，并有人在语言领域使用了这样的模块进行稀疏经验重放和局部适配，实现了终身学习文本分类和问答任务的最新成果。但是有三个缺点：(1)需要不切实际的大内存模块来实现良好的性能，(2)遭受负迁移，效果比原始效果差(3)每个测试示例需要多个本地自适应步骤，这显著降低了推理速度。
-   how当前研究到了哪一阶段

    首先，我们确定了三个作为**终身学习方法基础的共同原则**。我们试图描述他们在语言学习中的特点，并收集关于现有方法被忽视的缺点的见解。其次，基于这一分析，我们提出了一个整合这三个原则的**元终身框架**。我们的方法是d'Autume等人(2019)的直接扩展，它明确地元学习模型，作为局部适应的更好的初始化。最后，我们进行了广泛的**实验**，以证明我们提出的方法可以使用所确定的三个原则来实现有效的终身语言学习。
-   what作者基于什么样的假设（看不懂最后去查）
    

## ●Conclusion

-   优点
    
    实验证明了该框架在**文本分类和问答任务**中的有效性。我们报告新的最先进的结果，同时使用少100倍的**内存**空间。这些结果表明，通过建立**互补的学习系统**，实现**高效**的终身学习是可能的。我们的分析还表明，**负迁移**是一个被忽视的因素，可能导致次优的表现，我们强调了平衡灾难性遗忘和负迁移之间的平衡对未来工作的重要性。
-   缺点
    

## ●Table & Method

-   数据来源

将每个数据集视为一个单独的任务，模型需要一次学习同一类别的几个任务。
    
文本分类：来自张的五个数据集，跨越四个文本分类任务:(1)新闻分类(AGNews)，(2)情感分析(Yelp，Amazon)，(3)维基百科文章分类(DBPedia)和(4)问答分类(Yahoo)。

问题回答：三个问题回答数据集:SqL v 1.1(Rajpurkar等人，2016年)、TriviaQA (Joshi等人，2017年)和QuAC (Choi等人，2018年)。
-   重要指标
    
    文本分类：Accuracy ；问题回答： F1 scores
-   模型步骤（看不懂理论推导没关系）+ 每个步骤得出的结论

每个实验进行了四次，将结果取平均值。。

多任务学习的效果是终身学习效果的上限。

![](Efficient%20Meta%20Lifelong-Learning%20with%20Limited%20Memory%E6%9C%89%E9%99%90%E8%AE%B0%E5%BF%86%E7%9A%84%E9%AB%98%E6%95%88%E5%85%83%E7%BB%88%E8%BA%AB%E5%AD%A6%E4%B9%A0_md_files/image.png?v=1&type=image)
训练部分：
Input：训练集$D^{train}$；
Output：$θ$，存储器$M$
步骤：
1. 使用预训练模型初始化$θ$
2. [通用表示]对$θ$执行梯度更新以最小化等式$L_{TASK}^{meta}$
3. 如果训练步长等于0，则从存储器$M$中采样，
并[经验排练]对$θ$执行梯度更新以最小化等式。
5. 计算$p(x_t^i)$
6. 如果$Bernoulli(p(x_t^i))=1$，则将$(x_t^i, y_t^i)$添加到存储器$M$

测试部分：
Input：测试示例x；
Output：预测y
步骤
7. 从M中采样K个
8. [特定任务微调]对$θ$执行梯度更新以最小化等式$L_{LA}$
9. 输出预测 $y^i= f_θ(x^i)$

## Background: Principles of Lifelong Language Learning
式（1）：终身语言学习的目标：学习一个预测器$f_θ: X → Y$，例如一个神经网络，由$θ ∈ R^P$参数化，以最小化的所有任务的平均预期风险

语言学习最相关的共同的原则：

1. Generic Representation（通用表示）：跨不同任务传递知识的一个关键思想是学习一种能够为所有任务编码有用信息的通用表示
2. Experience Rehearsal（经验排练）：受补充学习系统（CLS）理论的激励，即人类依靠**情景记忆来存储过去的经验**并进行经验排练，我们还可以**对以前见过的任务重新训练**终身学习模型，以减少遗忘。
3. Task-specific Finetuning（特定于任务的微调）.注入特定于任务的参数和对单个任务进行微调对于不同的语言理解任务甚至是多种语言都是有效的。但是，所有这些方法都需要一个任务描述符，以便知道何时添加新参数。当不存在这样的信号时，**局部自适应**使用存储的每个测试示例的K个最近邻居在推理时执行额外的微调。预训练模型产生的句子嵌入可以有效地测量查询相似度，并且局部适应可以改善文本分类，问题回答和语言建模。

## 3 Proposed Framework

### 3.1 Model-based Parameter Adaptation
提出了MbPA ++的扩展，该扩展利用元学习范例来交织三个关键原则：（i）解决培训测试的差距，我们的框架学习适合于本地适应的通用表示形式，（ii）为了实现强大的本地适应性，内存模块使用基于分集的选择标准来减小内存大小，（iii）容纳较小的内存，框架利用粗略的本地适应性来缓解负向传输。

MbPA ++使用任何最新的文本编码器（例如BERT）来初始化预测器网络fθ和密钥网络gφ。

式（2）$L_{TASK}$：每一步加入一个训练样本，通过优化任务损失更新参数θ

式（3）$L_{REP}$：引入存储模块M，对于训练排练，根据重放样本与学习新样本的比例，随机选择M的子集S。用以避免灾难性遗忘。

式（4）$L_{LA}$：在推断时，在训练期间固定的key网络**gφ**用于将样本输入编码为密钥，以获得第i个测试示例xi的K个**最近邻居上下文**Nxi。然后执行局部适应梯度更新，以实现针对以下目标的**特定于任务的微调**

缺点：**牺牲大容量存储空间，慢推导速度**，根源在上面三个原则的过程是**独立**执行的，没有紧密交互。特别是：（i）学习的通用表示未针对本地适应性进行优化，因此需要更多步骤来增强性能，（ii）随机选择存储模块，并且缺乏有效地减小其大小的系统选择方法，（iii）对于每个测试示例，本地适应仅利用几个邻居，因此在内存较小时，它容易出现过度拟合和负传递的情况。

## 3.2 Synergistic Meta-lifelong Framework 协同元终身框架
我们提出了MbPA ++的扩展，该扩展利用元学习范例来交织三个关键原则：（i）解决训练测试的差距，我们的框架学习适合于本地适应的通用表示形式，（ii）为了实现强大的本地适应性，内存模块使用基于分集的选择标准来减小内存大小，（iii）容纳较小的内存，框架利用粗略的本地适应性来缓解负向传输。（算法1）
1. 通用表示。式（5）$L_{TASK}^{meta}$。我们将**局部适应**纳入训练通用表示。特别是，我们通过将局部适应性公式化为基本任务，并将表示学习作为元任务来阐述元学习的思想。也就是说，对通用表示进行了训练，使其在局部适应后也应表现良好（又称学习适应）。
2. 经验重放。式（6）$L_{REP}^{meta}$。根据与元任务损失相似的原理，我们将等式（3）中的内存重播损失重新格式化为元重播损失。式5和式6利用$L_{LA}$来限制参数的更新，目的是激发对所有任务的有效本地适应。

	使用与MbPA ++中相同的重放率（replay ratio）来保持元重放稀疏。提出了一种基于分集的选择标准，以确定是否应将训练示例（xi t，yi t）∈Dtrain添加到存储模块。在这里，我们**利用关键网络gφ通过xi到现有内存的最小距离来估计差异**（diversity），选择和当前内存中的任务差异大的加入存储器M，从而涵盖数据分发的不同部分。

3. 特定于任务的微调。将整个内存视为邻居，并从中随机抽样以与原始的局部适应公式（即相同的批次大小和梯度步长）进行比较。有两个好处：（1）对负迁移更可靠；（2）当我们将测试示例作为一个整体进行评估时，它更快。
